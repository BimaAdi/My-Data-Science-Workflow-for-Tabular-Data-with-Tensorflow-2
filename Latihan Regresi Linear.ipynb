{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan\n",
    "\n",
    "Gunakan data dari House Price (https://www.kaggle.com/c/house-prices-advanced-regression-techniques) yang pernah digunakan sebelumnya, gunakan model perceptron untuk mendapat hasil prediksinya lalu submit hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('dataset/train.csv')\n",
    "test_data = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# change data type column MSSubClass into object \n",
    "raw_data['MSSubClass'] = raw_data['MSSubClass'].astype('object')\n",
    "test_data['MSSubClass'] = test_data['MSSubClass'].astype('object')\n",
    "\n",
    "# remove and save column Id\n",
    "y = raw_data['SalePrice'].copy() # untuk Label\n",
    "raw_data.drop(columns=['Id', 'SalePrice'], inplace=True)\n",
    "test_Id = test_data['Id'].copy() # untuk submit kaggle\n",
    "test_data.drop(columns='Id', inplace=True)\n",
    "\n",
    "# combine raw_data (train) and test_data to single dataframe\n",
    "combine_data = pd.concat([raw_data.copy(), test_data.copy()])\n",
    "index_raw_data = list(range(len(raw_data)))\n",
    "index_test_data = list(range(len(raw_data), len(combine_data)))\n",
    "\n",
    "# FillNa categorical columns with 'NotAvail'\n",
    "columns_categorical = combine_data.select_dtypes('object').columns.values.tolist()\n",
    "for column in columns_categorical:\n",
    "    combine_data[column].fillna('NotAvail', inplace=True)\n",
    "    \n",
    "# FillNa numeric columns with 0 except 'LotFrontage' column\n",
    "columns_numeric = combine_data.select_dtypes('number').columns.values.tolist()\n",
    "for column in columns_numeric:\n",
    "    if column == 'LotFrontage':\n",
    "        combine_data[column].fillna(raw_data['LotFrontage'].median(skipna=True), inplace=True)\n",
    "    else:\n",
    "        combine_data[column].fillna(0, inplace=True)\n",
    "\n",
    "# one hot encoding categorical columns\n",
    "combine_data = pd.get_dummies(combine_data)\n",
    "\n",
    "# split combine data\n",
    "raw_data = combine_data.iloc[index_raw_data, :].copy()\n",
    "test_data = combine_data.iloc[index_test_data, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "normalize_X = raw_data.values\n",
    "normalize_y = y.values.reshape((1460, 1))\n",
    "normalize_X = X_scaler.fit_transform(normalize_X)\n",
    "normalize_y = y_scaler.fit_transform(normalize_y)\n",
    "\n",
    "normalize_y = normalize_y.reshape(1460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model 1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=311, units=1, kernel_initializer='uniform', activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model 2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=311, units=1, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# mae: 0.017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model 3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=311, units=1, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# mae: 0.168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model 4\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=311, units=1, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# mae: 0.168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1460/1460 [==============================] - 0s 206us/step - loss: 7.5940e-04 - mae: 0.0191\n",
      "Epoch 2/100\n",
      "1460/1460 [==============================] - 0s 170us/step - loss: 7.8533e-04 - mae: 0.0196\n",
      "Epoch 3/100\n",
      "1460/1460 [==============================] - 0s 166us/step - loss: 8.7855e-04 - mae: 0.0207\n",
      "Epoch 4/100\n",
      "1460/1460 [==============================] - 0s 150us/step - loss: 9.1208e-04 - mae: 0.0215\n",
      "Epoch 5/100\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: 9.4060e-04 - mae: 0.0213\n",
      "Epoch 6/100\n",
      "1460/1460 [==============================] - 0s 159us/step - loss: 9.1683e-04 - mae: 0.0209\n",
      "Epoch 7/100\n",
      "1460/1460 [==============================] - 0s 162us/step - loss: 9.3902e-04 - mae: 0.0217\n",
      "Epoch 8/100\n",
      "1460/1460 [==============================] - 0s 149us/step - loss: 7.7327e-04 - mae: 0.0194\n",
      "Epoch 9/100\n",
      "1460/1460 [==============================] - 0s 174us/step - loss: 7.1202e-04 - mae: 0.0184\n",
      "Epoch 10/100\n",
      "1460/1460 [==============================] - 0s 177us/step - loss: 8.9272e-04 - mae: 0.0212\n",
      "Epoch 11/100\n",
      "1460/1460 [==============================] - 0s 164us/step - loss: 0.0011 - mae: 0.0242\n",
      "Epoch 12/100\n",
      "1460/1460 [==============================] - 0s 172us/step - loss: 9.9537e-04 - mae: 0.0219\n",
      "Epoch 13/100\n",
      "1460/1460 [==============================] - 0s 154us/step - loss: 0.0010 - mae: 0.0225\n",
      "Epoch 14/100\n",
      "1460/1460 [==============================] - 0s 171us/step - loss: 8.8895e-04 - mae: 0.0207\n",
      "Epoch 15/100\n",
      "1460/1460 [==============================] - 0s 151us/step - loss: 7.2068e-04 - mae: 0.0187\n",
      "Epoch 16/100\n",
      "1460/1460 [==============================] - 0s 165us/step - loss: 9.0309e-04 - mae: 0.0211\n",
      "Epoch 17/100\n",
      "1460/1460 [==============================] - 0s 169us/step - loss: 7.4175e-04 - mae: 0.0190\n",
      "Epoch 18/100\n",
      "1460/1460 [==============================] - 0s 238us/step - loss: 7.4967e-04 - mae: 0.0190\n",
      "Epoch 19/100\n",
      "1460/1460 [==============================] - 0s 174us/step - loss: 7.6154e-04 - mae: 0.0190\n",
      "Epoch 20/100\n",
      "1460/1460 [==============================] - 0s 156us/step - loss: 8.2449e-04 - mae: 0.0204\n",
      "Epoch 21/100\n",
      "1460/1460 [==============================] - 0s 159us/step - loss: 7.8400e-04 - mae: 0.0196\n",
      "Epoch 22/100\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: 7.6599e-04 - mae: 0.0193\n",
      "Epoch 23/100\n",
      "1460/1460 [==============================] - 0s 158us/step - loss: 7.2426e-04 - mae: 0.0186\n",
      "Epoch 24/100\n",
      "1460/1460 [==============================] - 0s 167us/step - loss: 7.1882e-04 - mae: 0.0188\n",
      "Epoch 25/100\n",
      "1460/1460 [==============================] - 0s 156us/step - loss: 7.7310e-04 - mae: 0.0196\n",
      "Epoch 26/100\n",
      "1460/1460 [==============================] - 0s 241us/step - loss: 8.1562e-04 - mae: 0.0202\n",
      "Epoch 27/100\n",
      "1460/1460 [==============================] - 0s 171us/step - loss: 7.3589e-04 - mae: 0.0193\n",
      "Epoch 28/100\n",
      "1460/1460 [==============================] - 0s 158us/step - loss: 7.7319e-04 - mae: 0.0193\n",
      "Epoch 29/100\n",
      "1460/1460 [==============================] - 0s 161us/step - loss: 7.9754e-04 - mae: 0.0196\n",
      "Epoch 30/100\n",
      "1460/1460 [==============================] - 0s 157us/step - loss: 6.9737e-04 - mae: 0.0183\n",
      "Epoch 31/100\n",
      "1460/1460 [==============================] - 0s 227us/step - loss: 7.7329e-04 - mae: 0.0196\n",
      "Epoch 32/100\n",
      "1460/1460 [==============================] - 0s 185us/step - loss: 8.6253e-04 - mae: 0.0208\n",
      "Epoch 33/100\n",
      "1460/1460 [==============================] - 0s 165us/step - loss: 7.5694e-04 - mae: 0.0189\n",
      "Epoch 34/100\n",
      "1460/1460 [==============================] - 0s 154us/step - loss: 7.0087e-04 - mae: 0.0183\n",
      "Epoch 35/100\n",
      "1460/1460 [==============================] - 0s 228us/step - loss: 7.3184e-04 - mae: 0.0186\n",
      "Epoch 36/100\n",
      "1460/1460 [==============================] - 0s 188us/step - loss: 7.7452e-04 - mae: 0.0193\n",
      "Epoch 37/100\n",
      "1460/1460 [==============================] - 0s 171us/step - loss: 8.4783e-04 - mae: 0.0206\n",
      "Epoch 38/100\n",
      "1184/1460 [=======================>......] - ETA: 0s - loss: 7.4283e-04 - mae: 0.0188"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(normalize_X, normalize_y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test_data\n",
    "test_values = test_data.values\n",
    "test_values = X_scaler.transform(test_values)\n",
    "\n",
    "# predict data test\n",
    "test_predict = model.predict(test_values)\n",
    "\n",
    "# inverse transform predict\n",
    "test_predict = test_predict.reshape((1459, 1))\n",
    "test_predict = y_scaler.inverse_transform(test_predict)\n",
    "test_predict = test_predict.reshape(1459)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Submission\n",
    "kaggle_submission = pd.DataFrame({\n",
    "    'Id': test_Id,\n",
    "    'SalePrice': test_predict\n",
    "})\n",
    "\n",
    "kaggle_submission.to_csv('neural_network4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
